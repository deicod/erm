package generator

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"

	"github.com/deicod/erm/internal/orm/dsl"
	"gopkg.in/yaml.v3"
)

type generatorOptions struct {
	GenerateOptions
	Now func() time.Time
}

type MigrationResult struct {
	Operations []Operation
	SQL        string
	FilePath   string
	Snapshot   SchemaSnapshot
}

func (opts generatorOptions) now() time.Time {
	if opts.Now != nil {
		return opts.Now()
	}
	return time.Now().UTC()
}

func generateMigrations(root string, entities []Entity, opts generatorOptions) (MigrationResult, error) {
	result := MigrationResult{}
	dir := filepath.Join(root, "migrations")
	if err := os.MkdirAll(dir, 0o755); err != nil {
		return result, err
	}

	prev, err := loadSchemaSnapshot(root)
	if err != nil {
		return result, err
	}

	cfg := loadProjectConfig(root)
	usage := detectExtensionUsage(entities)
	flags := extensionFlags{
		postgis:   cfg.Extensions.PostGIS || usage.postgis,
		pgvector:  cfg.Extensions.PGVector || usage.pgvector,
		timescale: cfg.Extensions.Timescale || usage.timescale,
	}

	next := buildSchemaSnapshot(entities, flags)
	ops := diffSchema(prev, next)
	result.Operations = ops
	result.Snapshot = prev
	if len(ops) == 0 {
		if opts.Force {
			result.Snapshot = next
			if !opts.DryRun {
				if err := writeSchemaSnapshot(root, next); err != nil {
					return result, err
				}
			}
		}
		return result, nil
	}

	sql := renderMigrationSQL(ops)
	result.SQL = sql
	result.Snapshot = next

	if opts.DryRun {
		return result, nil
	}

	timestamp := opts.now().UTC().Format("20060102150405")
	slug := opts.MigrationName
	if slug == "" {
		slug = defaultMigrationSlug(ops)
	}
	slug = slugify(slug)
	filename := fmt.Sprintf("%s_%s.sql", timestamp, slug)
	path := filepath.Join(dir, filename)
	if err := writeFile(path, []byte(sql)); err != nil {
		return result, err
	}
	if err := writeSchemaSnapshot(root, next); err != nil {
		return result, err
	}
	result.FilePath = path
	return result, nil
}

func renderMigrationSQL(ops []Operation) string {
	buf := &bytes.Buffer{}
	buf.WriteString("-- Code generated by erm.\n")
	buf.WriteString("-- Schema migration.\n\n")
	for i, op := range ops {
		buf.WriteString(op.SQL)
		if !strings.HasSuffix(op.SQL, "\n") {
			buf.WriteString("\n")
		}
		if i < len(ops)-1 {
			buf.WriteString("\n")
		}
	}
	return buf.String()
}

func defaultMigrationSlug(ops []Operation) string {
	if len(ops) == 0 {
		return "schema"
	}
	op := ops[0]
	target := op.Target
	switch op.Kind {
	case OpCreateTable:
		if target != "" {
			return fmt.Sprintf("create_%s", target)
		}
	case OpDropTable:
		if target != "" {
			return fmt.Sprintf("drop_%s", target)
		}
	case OpAddColumn:
		if target != "" {
			return fmt.Sprintf("add_%s", strings.ReplaceAll(target, ".", "_"))
		}
	case OpDropColumn:
		if target != "" {
			return fmt.Sprintf("drop_%s", strings.ReplaceAll(target, ".", "_"))
		}
	case OpAddIndex:
		if target != "" {
			return fmt.Sprintf("add_%s", target)
		}
	case OpDropIndex:
		if target != "" {
			return fmt.Sprintf("drop_%s", target)
		}
	}
	if target != "" {
		parts := strings.Split(target, ".")
		return parts[len(parts)-1]
	}
	return "schema"
}

var slugNormalizer = regexp.MustCompile(`[^a-z0-9]+`)

func slugify(name string) string {
	normalized := strings.ToLower(strings.TrimSpace(name))
	if normalized == "" {
		return "schema"
	}
	normalized = slugNormalizer.ReplaceAllString(normalized, "_")
	normalized = strings.Trim(normalized, "_")
	if normalized == "" {
		return "schema"
	}
	return normalized
}

type entityMigration struct {
	Entity      Entity
	Fields      []dsl.Field
	ForeignKeys []foreignKeySpec
	fieldIndex  map[string]int
	fkIndex     map[string]struct{}
}

type foreignKeySpec struct {
	Column        string
	TargetTable   string
	TargetColumn  string
	ConstraintKey string
	OnDelete      dsl.CascadeAction
	OnUpdate      dsl.CascadeAction
}

type joinTableSpec struct {
	Name  string
	Left  joinTableColumn
	Right joinTableColumn
}

type joinTableColumn struct {
	Column       string
	TargetTable  string
	TargetColumn string
	SQLType      string
	OnDelete     dsl.CascadeAction
	OnUpdate     dsl.CascadeAction
}

func renderInitialMigration(entities []Entity, flags extensionFlags) string {
	buf := &bytes.Buffer{}
	buf.WriteString("-- Code generated by erm.\n")
	buf.WriteString("-- Initial schema migration.\n\n")
	if flags.postgis {
		buf.WriteString("CREATE EXTENSION IF NOT EXISTS postgis;\n")
	}
	if flags.pgvector {
		buf.WriteString("CREATE EXTENSION IF NOT EXISTS vector;\n")
	}
	if flags.timescale {
		buf.WriteString("CREATE EXTENSION IF NOT EXISTS timescaledb;\n")
	}
	if flags.postgis || flags.pgvector || flags.timescale {
		buf.WriteString("\n")
	}
	migrationEntities, joinTables := buildMigrationPlan(entities)
	sort.Slice(migrationEntities, func(i, j int) bool { return migrationEntities[i].Entity.Name < migrationEntities[j].Entity.Name })
	var deferredFKs []string
	for _, ent := range migrationEntities {
		table := pluralize(ent.Entity.Name)
		buf.WriteString(fmt.Sprintf("CREATE TABLE IF NOT EXISTS %s (\n", table))
		cols := make([]string, 0, len(ent.Fields)+1)
		primaryCols := make([]string, 0, 1)
		var hypertableColumn string
		for _, field := range ent.Fields {
			column := fieldColumn(field)
			colDef := fmt.Sprintf("    %s %s", column, fieldSQLType(field))
			if !field.Nullable {
				colDef += " NOT NULL"
			}
			if field.IsPrimary {
				primaryCols = append(primaryCols, column)
			}
			if field.HasDefaultNow {
				colDef += " DEFAULT now()"
			} else if field.DefaultExpr != "" {
				colDef += fmt.Sprintf(" DEFAULT %s", field.DefaultExpr)
			}
			if field.IsUnique {
				colDef += " UNIQUE"
			}
			if ts, ok := field.Annotations["timeseries"].(bool); ok && ts {
				hypertableColumn = column
			}
			cols = append(cols, colDef)
		}
		if len(primaryCols) > 0 {
			cols = append(cols, fmt.Sprintf("    PRIMARY KEY (%s)", strings.Join(primaryCols, ", ")))
		}
		buf.WriteString(strings.Join(cols, ",\n"))
		buf.WriteString("\n);\n\n")

		for _, fk := range ent.ForeignKeys {
			deferredFKs = append(deferredFKs, foreignKeySQL(table, fk))
		}

		// Indexes
		for _, idx := range ent.Entity.Indexes {
			method := ""
			if idx.Method != "" {
				method = fmt.Sprintf(" USING %s", idx.Method)
			}
			unique := ""
			if idx.IsUnique {
				unique = " UNIQUE"
			}
			where := ""
			if idx.Where != "" {
				where = fmt.Sprintf(" WHERE %s", idx.Where)
			}
			cols := strings.Join(idx.Columns, ", ")
			buf.WriteString(fmt.Sprintf("CREATE%s INDEX IF NOT EXISTS %s ON %s%s (%s)%s;\n\n", unique, idx.Name, table, method, cols, where))
		}

		if hypertableColumn != "" {
			buf.WriteString(fmt.Sprintf("SELECT create_hypertable('%s', '%s', if_not_exists => TRUE);\n\n", table, hypertableColumn))
		}
	}
	if len(deferredFKs) > 0 {
		for _, stmt := range deferredFKs {
			buf.WriteString(stmt)
			buf.WriteString("\n")
		}
		buf.WriteString("\n")
	}
	if len(joinTables) > 0 {
		sort.Slice(joinTables, func(i, j int) bool { return joinTables[i].Name < joinTables[j].Name })
		for _, jt := range joinTables {
			buf.WriteString(fmt.Sprintf("CREATE TABLE IF NOT EXISTS %s (\n", jt.Name))
			cols := []string{
				fmt.Sprintf("    %s %s NOT NULL", jt.Left.Column, jt.Left.SQLType),
				fmt.Sprintf("    %s %s NOT NULL", jt.Right.Column, jt.Right.SQLType),
				fmt.Sprintf("    PRIMARY KEY (%s, %s)", jt.Left.Column, jt.Right.Column),
				joinTableConstraint(jt.Name, jt.Left),
				joinTableConstraint(jt.Name, jt.Right),
			}
			buf.WriteString(strings.Join(cols, ",\n"))
			buf.WriteString("\n);\n\n")
		}
	}
	return buf.String()
}

func buildMigrationPlan(entities []Entity) ([]entityMigration, []joinTableSpec) {
	// Migrations operate on the fully-derived entity metadata so generated DDL
	// mirrors the defaults and overrides resolved by the DSL parser.
	plan := make([]entityMigration, len(entities))
	entityIndex := make(map[string]*entityMigration, len(entities))
	for i, ent := range entities {
		fields := make([]dsl.Field, len(ent.Fields))
		copy(fields, ent.Fields)
		fieldIndex := make(map[string]int, len(fields))
		for idx, field := range fields {
			fieldIndex[fieldColumn(field)] = idx
		}
		plan[i] = entityMigration{
			Entity:      ent,
			Fields:      fields,
			ForeignKeys: []foreignKeySpec{},
			fieldIndex:  fieldIndex,
			fkIndex:     map[string]struct{}{},
		}
		entityIndex[ent.Name] = &plan[i]
	}

	joinTableMap := map[string]joinTableSpec{}

	for i := range plan {
		src := &plan[i]
		srcPrimary, ok := findPrimaryField(src.Entity)
		if !ok {
			continue
		}
		for _, edge := range src.Entity.Edges {
			switch edge.Kind {
			case dsl.EdgeToOne:
				ensureToOneColumn(src, entityIndex, edge)
			case dsl.EdgeToMany:
				ensureToManyColumn(src, entityIndex, edge, srcPrimary)
			case dsl.EdgeManyToMany:
				ensureJoinTable(joinTableMap, src.Entity, entityIndex, edge, srcPrimary)
			}
		}
	}

	joinTables := make([]joinTableSpec, 0, len(joinTableMap))
	for _, jt := range joinTableMap {
		joinTables = append(joinTables, jt)
	}
	return plan, joinTables
}

func ensureToOneColumn(src *entityMigration, entityIndex map[string]*entityMigration, edge dsl.Edge) {
	target, ok := entityIndex[edge.Target]
	if !ok {
		return
	}
	targetPrimary, ok := findPrimaryField(target.Entity)
	if !ok {
		return
	}
	column := edgeColumn(edge)
	if column == "" {
		return
	}
	fkField := makeForeignKeyField(column, targetPrimary, edge.Nullable, edge.Unique)
	if idx, exists := src.fieldIndex[column]; exists {
		existing := src.Fields[idx]
		if edge.Nullable && !existing.Nullable {
			existing.Nullable = true
		}
		if edge.Unique && !existing.IsUnique {
			existing.IsUnique = true
		}
		src.Fields[idx] = existing
	} else {
		src.Fields = append(src.Fields, fkField)
		src.fieldIndex[column] = len(src.Fields) - 1
	}
	constraint := fmt.Sprintf("fk_%s_%s", pluralize(src.Entity.Name), column)
	if _, exists := src.fkIndex[column]; !exists {
		src.ForeignKeys = append(src.ForeignKeys, foreignKeySpec{
			Column:        column,
			TargetTable:   pluralize(edge.Target),
			TargetColumn:  fieldColumn(targetPrimary),
			ConstraintKey: constraint,
			OnDelete:      edge.Cascade.OnDelete,
			OnUpdate:      edge.Cascade.OnUpdate,
		})
		src.fkIndex[column] = struct{}{}
	}
}

func ensureToManyColumn(src *entityMigration, entityIndex map[string]*entityMigration, edge dsl.Edge, srcPrimary dsl.Field) {
	target, ok := entityIndex[edge.Target]
	if !ok {
		return
	}
	refColumn := edgeRefColumn(src.Entity, edge, srcPrimary)
	if refColumn == "" {
		return
	}
	fkField := makeForeignKeyField(refColumn, srcPrimary, edge.Nullable, edge.Unique)
	if idx, exists := target.fieldIndex[refColumn]; exists {
		existing := target.Fields[idx]
		if edge.Nullable && !existing.Nullable {
			existing.Nullable = true
		}
		if edge.Unique && !existing.IsUnique {
			existing.IsUnique = true
		}
		target.Fields[idx] = existing
	} else {
		target.Fields = append(target.Fields, fkField)
		target.fieldIndex[refColumn] = len(target.Fields) - 1
	}
	constraint := fmt.Sprintf("fk_%s_%s", pluralize(target.Entity.Name), refColumn)
	if _, exists := target.fkIndex[refColumn]; !exists {
		target.ForeignKeys = append(target.ForeignKeys, foreignKeySpec{
			Column:        refColumn,
			TargetTable:   pluralize(src.Entity.Name),
			TargetColumn:  fieldColumn(srcPrimary),
			ConstraintKey: constraint,
			OnDelete:      edge.Cascade.OnDelete,
			OnUpdate:      edge.Cascade.OnUpdate,
		})
		target.fkIndex[refColumn] = struct{}{}
	}
}

func ensureJoinTable(joinTables map[string]joinTableSpec, source Entity, entityIndex map[string]*entityMigration, edge dsl.Edge, srcPrimary dsl.Field) {
	target, ok := entityIndex[edge.Target]
	if !ok {
		return
	}
	targetPrimary, ok := findPrimaryField(target.Entity)
	if !ok {
		return
	}
	joinName, leftColumn, rightColumn := manyToManyJoinSpec(source, srcPrimary, edge, targetPrimary)
	if joinName == "" || leftColumn == "" || rightColumn == "" {
		return
	}
	key := joinName
	if key == "" {
		key = joinName
	}
	if _, exists := joinTables[key]; exists {
		return
	}
	joinTables[key] = joinTableSpec{
		Name: joinName,
		Left: joinTableColumn{
			Column:       leftColumn,
			TargetTable:  pluralize(source.Name),
			TargetColumn: fieldColumn(srcPrimary),
			SQLType:      fieldSQLType(srcPrimary),
			OnDelete:     edge.Cascade.OnDelete,
			OnUpdate:     edge.Cascade.OnUpdate,
		},
		Right: joinTableColumn{
			Column:       rightColumn,
			TargetTable:  pluralize(edge.Target),
			TargetColumn: fieldColumn(targetPrimary),
			SQLType:      fieldSQLType(targetPrimary),
			OnDelete:     edge.Cascade.OnDelete,
			OnUpdate:     edge.Cascade.OnUpdate,
		},
	}
}

func makeForeignKeyField(column string, refField dsl.Field, nullable, unique bool) dsl.Field {
	field := dsl.Field{
		Name:     column,
		Column:   column,
		Type:     refField.Type,
		GoType:   refField.GoType,
		Nullable: nullable,
		IsUnique: unique,
	}
	return field
}

func findPrimaryField(ent Entity) (dsl.Field, bool) {
	for _, field := range ent.Fields {
		if field.IsPrimary {
			return field, true
		}
	}
	if len(ent.Fields) > 0 {
		return ent.Fields[0], true
	}
	return dsl.Field{}, false
}

func foreignKeySQL(table string, fk foreignKeySpec) string {
	clause := fmt.Sprintf("ALTER TABLE %s ADD CONSTRAINT %s FOREIGN KEY (%s) REFERENCES %s (%s)", table, fk.ConstraintKey, fk.Column, fk.TargetTable, fk.TargetColumn)
	if fk.OnDelete != "" {
		clause += fmt.Sprintf(" ON DELETE %s", fk.OnDelete)
	}
	if fk.OnUpdate != "" {
		clause += fmt.Sprintf(" ON UPDATE %s", fk.OnUpdate)
	}
	return clause + ";"
}

func joinTableConstraint(table string, col joinTableColumn) string {
	clause := fmt.Sprintf("    CONSTRAINT %s FOREIGN KEY (%s) REFERENCES %s (%s)", fkConstraintName(table, col.Column), col.Column, col.TargetTable, col.TargetColumn)
	if col.OnDelete != "" {
		clause += fmt.Sprintf(" ON DELETE %s", col.OnDelete)
	}
	if col.OnUpdate != "" {
		clause += fmt.Sprintf(" ON UPDATE %s", col.OnUpdate)
	}
	return clause
}

func fieldSQLType(field dsl.Field) string {
	base := sqlTypeLiteral(field)
	if isIdentityColumn(field) {
		mode := "BY DEFAULT"
		if m, ok := field.Annotations["identity_mode"].(string); ok && m == string(dsl.IdentityAlways) {
			mode = "ALWAYS"
		}
		base = fmt.Sprintf("%s GENERATED %s AS IDENTITY", base, mode)
	}
	return base
}

func sqlTypeLiteral(field dsl.Field) string {
	switch field.Type {
	case dsl.TypeUUID:
		return "uuid"
	case dsl.TypeText:
		return "text"
	case dsl.TypeVarChar:
		if size := annotationInt(field, "length"); size > 0 {
			return fmt.Sprintf("varchar(%d)", size)
		}
		return "varchar"
	case dsl.TypeChar:
		if size := annotationInt(field, "length"); size > 0 {
			return fmt.Sprintf("char(%d)", size)
		}
		return "char"
	case dsl.TypeBoolean:
		return "boolean"
	case dsl.TypeSmallInt:
		return "smallint"
	case dsl.TypeInteger:
		return "integer"
	case dsl.TypeBigInt:
		return "bigint"
	case dsl.TypeSmallSerial:
		return "smallserial"
	case dsl.TypeSerial:
		return "serial"
	case dsl.TypeBigSerial:
		return "bigserial"
	case dsl.TypeDecimal, dsl.TypeNumeric:
		precision := annotationInt(field, "precision")
		scale := annotationInt(field, "scale")
		base := string(field.Type)
		if precision > 0 && scale >= 0 {
			return fmt.Sprintf("%s(%d,%d)", base, precision, scale)
		}
		if precision > 0 {
			return fmt.Sprintf("%s(%d)", base, precision)
		}
		return base
	case dsl.TypeReal:
		return "real"
	case dsl.TypeDoublePrecision:
		return "double precision"
	case dsl.TypeMoney:
		return "money"
	case dsl.TypeBytea:
		return "bytea"
	case dsl.TypeDate:
		return "date"
	case dsl.TypeTime:
		if precision := annotationInt(field, "precision"); precision > 0 {
			return fmt.Sprintf("time(%d)", precision)
		}
		return "time"
	case dsl.TypeTimeTZ:
		if precision := annotationInt(field, "precision"); precision > 0 {
			return fmt.Sprintf("timetz(%d)", precision)
		}
		return "timetz"
	case dsl.TypeTimestamp:
		if precision := annotationInt(field, "precision"); precision > 0 {
			return fmt.Sprintf("timestamp(%d)", precision)
		}
		return "timestamp"
	case dsl.TypeTimestampTZ:
		if precision := annotationInt(field, "precision"); precision > 0 {
			return fmt.Sprintf("timestamptz(%d)", precision)
		}
		return "timestamptz"
	case dsl.TypeInterval:
		if precision := annotationInt(field, "precision"); precision > 0 {
			return fmt.Sprintf("interval(%d)", precision)
		}
		return "interval"
	case dsl.TypeJSON:
		return "json"
	case dsl.TypeJSONB:
		return "jsonb"
	case dsl.TypeXML:
		return "xml"
	case dsl.TypeInet:
		return "inet"
	case dsl.TypeCIDR:
		return "cidr"
	case dsl.TypeMACAddr:
		return "macaddr"
	case dsl.TypeMACAddr8:
		return "macaddr8"
	case dsl.TypeBit:
		if size := annotationInt(field, "length"); size > 0 {
			return fmt.Sprintf("bit(%d)", size)
		}
		return "bit"
	case dsl.TypeVarBit:
		if size := annotationInt(field, "length"); size > 0 {
			return fmt.Sprintf("varbit(%d)", size)
		}
		return "varbit"
	case dsl.TypeTSVector:
		return "tsvector"
	case dsl.TypeTSQuery:
		return "tsquery"
	case dsl.TypePoint:
		return "point"
	case dsl.TypeLine:
		return "line"
	case dsl.TypeLseg:
		return "lseg"
	case dsl.TypeBox:
		return "box"
	case dsl.TypePath:
		return "path"
	case dsl.TypePolygon:
		return "polygon"
	case dsl.TypeCircle:
		return "circle"
	case dsl.TypeInt4Range:
		return "int4range"
	case dsl.TypeInt8Range:
		return "int8range"
	case dsl.TypeNumRange:
		return "numrange"
	case dsl.TypeTSRange:
		return "tsrange"
	case dsl.TypeTSTZRange:
		return "tstzrange"
	case dsl.TypeDateRange:
		return "daterange"
	case dsl.TypeArray:
		elem, _ := field.Annotations["array_element"].(dsl.FieldType)
		if elem == "" {
			return "text[]"
		}
		elementField := dsl.Field{Type: elem}
		return fmt.Sprintf("%s[]", sqlTypeLiteral(elementField))
	case dsl.TypeGeometry:
		return "geometry"
	case dsl.TypeGeography:
		return "geography"
	case dsl.TypeVector:
		if dim, ok := field.Annotations["vector_dim"].(int); ok && dim > 0 {
			return fmt.Sprintf("vector(%d)", dim)
		}
		return "vector"
	default:
		if custom := string(field.Type); custom != "" {
			return custom
		}
		return "text"
	}
}

func annotationInt(field dsl.Field, key string) int {
	if v, ok := field.Annotations[key]; ok {
		switch val := v.(type) {
		case int:
			return val
		case int32:
			return int(val)
		case int64:
			return int(val)
		}
	}
	return 0
}

func isIdentityColumn(field dsl.Field) bool {
	if field.Annotations == nil {
		return false
	}
	if v, ok := field.Annotations["identity"].(bool); !ok || !v {
		return false
	}
	switch field.Type {
	case dsl.TypeSmallInt, dsl.TypeInteger, dsl.TypeBigInt:
		return true
	}
	return false
}

type projectConfig struct {
	Extensions struct {
		PostGIS   bool `yaml:"postgis"`
		PGVector  bool `yaml:"pgvector"`
		Timescale bool `yaml:"timescaledb"`
	} `yaml:"extensions"`
}

type extensionFlags struct {
	postgis   bool
	pgvector  bool
	timescale bool
}

func loadProjectConfig(root string) projectConfig {
	path := filepath.Join(root, "erm.yaml")
	raw, err := os.ReadFile(path)
	if err != nil {
		return projectConfig{}
	}
	var cfg projectConfig
	if err := yaml.Unmarshal(raw, &cfg); err != nil {
		return projectConfig{}
	}
	return cfg
}

func detectExtensionUsage(entities []Entity) extensionFlags {
	var flags extensionFlags
	for _, ent := range entities {
		for _, field := range ent.Fields {
			switch field.Type {
			case dsl.TypeGeometry, dsl.TypeGeography:
				flags.postgis = true
			case dsl.TypeVector:
				flags.pgvector = true
			}
			if ts, ok := field.Annotations["timeseries"].(bool); ok && ts {
				flags.timescale = true
			}
		}
	}
	return flags
}
